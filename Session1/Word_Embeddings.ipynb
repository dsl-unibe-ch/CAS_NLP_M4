{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison of Text embedding with BOW, Word2Vec and BERT"
      ],
      "metadata": {
        "id": "Qk9jgnDnpKbL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZJ4ASXFnf8H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import gensim.downloader as api\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = [\"I want a dog\"]\n",
        "\n",
        "# Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "bow_representation = vectorizer.fit_transform(text).toarray()\n",
        "print(\"Bag of Words Representation:\", bow_representation)\n",
        "print(\"Bag of Words Vocabulary:\", vectorizer.get_feature_names_out())\n",
        "print(f\"Shape of the vector embedding {bow_representation.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QqYiVGkn6dl",
        "outputId": "2f7600ec-b56e-4be6-fc2f-176d16032d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words Representation: [[1 1]]\n",
            "Bag of Words Vocabulary: ['dog' 'want']\n",
            "Shape of the vector embedding (1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Word2Vec\n",
        "try:\n",
        "    word2vec_model = api.load(\"word2vec-google-news-300\")\n",
        "    word2vec_representation = np.array([word2vec_model[word] for word in text[0].split() if word in word2vec_model])\n",
        "    avg_representation = np.mean(word2vec_representation, axis=0)\n",
        "    print(\"\\nWord2Vec Representation (averaged):\",avg_representation )\n",
        "    print(f\"Shape of the vector embedding {word2vec_representation.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nCould not load Word2Vec model or process text: {e}\")\n",
        "    print(\"Please try again later or with a different model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaBOTUmbn85s",
        "outputId": "7796beb2-a3ce-4154-c231-f5a24d58d698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word2Vec Representation (averaged): [ 0.08902995  0.04035441  0.01790365  0.14794922 -0.04020182  0.01212565\n",
            "  0.12491862 -0.0797526  -0.01969401  0.02441406  0.02881114 -0.26985678\n",
            " -0.00665283 -0.13582356 -0.11905924  0.12174479 -0.01155599  0.1451009\n",
            "  0.0172526  -0.10123698 -0.02775065  0.0390625   0.18945312 -0.05777995\n",
            " -0.01171875  0.09675089 -0.10576773  0.0867513   0.12882487 -0.03503418\n",
            "  0.03792318  0.08268229 -0.03808594 -0.11669922  0.01147461  0.0659078\n",
            "  0.10587565  0.07470703  0.03924561  0.19921875  0.09041341 -0.1398112\n",
            "  0.16164143  0.02799479 -0.06738281 -0.00813802  0.10469564 -0.02921549\n",
            " -0.01257324 -0.0061849  -0.05794271  0.13102214  0.09729004  0.06083171\n",
            "  0.05541992  0.06467692  0.08243815 -0.05696614  0.17020671 -0.05094401\n",
            "  0.14697266  0.1007487  -0.08300781  0.01670329  0.03487142 -0.06624349\n",
            " -0.10990397  0.14526367 -0.05529785 -0.00066121  0.21940105  0.12379964\n",
            " -0.00854492  0.02742513 -0.29101562 -0.14650472  0.16243489  0.02676392\n",
            "  0.15901692  0.04329427  0.0205485  -0.06437174  0.1361491  -0.05940755\n",
            " -0.20475261 -0.10302734 -0.14542644  0.19824219  0.04218038 -0.05875651\n",
            " -0.05875651  0.04711914 -0.13102214 -0.09106445 -0.08463541 -0.18412273\n",
            "  0.11808268  0.10282389 -0.04982503 -0.09944662 -0.2076823  -0.04915364\n",
            "  0.07145182  0.14575195 -0.03531901 -0.00195312 -0.06445312 -0.06933594\n",
            "  0.06009929 -0.07387289 -0.26660156 -0.0061849   0.03181966  0.05635579\n",
            "  0.10595703 -0.10620117 -0.03006999 -0.24088542 -0.01310221 -0.0764974\n",
            " -0.0900472   0.02124023 -0.10654704  0.14444987 -0.05224609 -0.078125\n",
            " -0.11425781 -0.12386068  0.01472982 -0.12679036 -0.19319661 -0.11710612\n",
            " -0.22363281  0.02709961 -0.12109375 -0.12858073  0.01717885  0.04248047\n",
            "  0.16276042  0.2076823   0.00101725 -0.03426107 -0.01139323 -0.01806641\n",
            "  0.04667537  0.08455404 -0.14176433 -0.19718425 -0.00252279 -0.15488689\n",
            "  0.21582031  0.12776692 -0.20019531 -0.04052734 -0.06245931  0.07788086\n",
            "  0.01184082 -0.04939779 -0.125       0.07014974  0.06656901  0.04012044\n",
            "  0.07291666  0.10758463  0.0287679  -0.12778728  0.04045932  0.00073242\n",
            "  0.12972005 -0.08837891 -0.13028972  0.00846354 -0.00838216  0.00057983\n",
            " -0.1381836   0.01342773  0.19108073 -0.01582845 -0.15364583  0.1373698\n",
            " -0.09020996  0.01745605  0.04296875  0.10424805 -0.02164713 -0.04884847\n",
            " -0.01936849  0.1694336   0.13305664  0.05037435 -0.00097656  0.07263184\n",
            "  0.02868652  0.04500325  0.18782552  0.06445312 -0.05566406 -0.03072103\n",
            " -0.10668945 -0.13053386 -0.08723959  0.01871745 -0.07763672 -0.04671224\n",
            " -0.02738444 -0.0008138  -0.10420736  0.04222615  0.15039062 -0.03125\n",
            " -0.13663737  0.0699056  -0.07242838  0.01981608 -0.1985677  -0.00431315\n",
            "  0.1977539  -0.06087239 -0.1516927  -0.07373047 -0.06282552 -0.06087239\n",
            " -0.09718832 -0.09847005  0.03222656 -0.17377727  0.18554688 -0.01456706\n",
            "  0.01188151 -0.10286459  0.02357992 -0.0316569  -0.10786947  0.10135905\n",
            "  0.04361979  0.09098307  0.03556315  0.0863444   0.15755208 -0.0160319\n",
            "  0.08873495 -0.05932617  0.04134114 -0.09138998  0.01611328  0.06005859\n",
            " -0.01121012  0.11866251 -0.01114909 -0.09301758 -0.02897135  0.05582682\n",
            "  0.00415039  0.04492188  0.0078125   0.05362956 -0.03475952 -0.08215332\n",
            " -0.20751953 -0.14111328 -0.11564127  0.01733398 -0.07063802  0.04370117\n",
            "  0.08170573  0.07910156 -0.0501709   0.01147461 -0.21647136  0.09261068\n",
            "  0.02840169  0.17985027  0.17805989  0.26464844 -0.02099609 -0.14567058\n",
            " -0.00630061 -0.08610026 -0.04394531 -0.01784515  0.1336263  -0.05638377\n",
            "  0.05314128  0.22167969 -0.05598958  0.01009115 -0.06139119 -0.03369141\n",
            "  0.01236979  0.10432943 -0.14225261  0.1171875  -0.20564778  0.04833984\n",
            "  0.02734375 -0.07250977  0.04785156  0.07554118 -0.08943685  0.02579753]\n",
            "Shape of the vector embedding (3, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# BERT\n",
        "try:\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "\n",
        "    # Using the representation of the [CLS] token\n",
        "    bert_representation = output.last_hidden_state[:, 0, :].numpy()\n",
        "    print(\"\\nBERT Representation ([CLS] token):\", bert_representation)\n",
        "    print(f\"Shape of the vector embedding {bert_representation.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nCould not load BERT model or process text: {e}\")\n",
        "    print(\"Please try again later or with a different model.\")"
      ],
      "metadata": {
        "id": "yHGfY0DJn-J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "#model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "model.eval()\n",
        "\n",
        "encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "with torch.no_grad():\n",
        "    out = model(**encoded)  # out.last_hidden_state: [batch, seq_len, hidden=768]\n",
        "\n",
        "# mean pooling with attention mask\n",
        "token_embeddings = out.last_hidden_state                  # [1, L, 768]\n",
        "print(token_embeddings)\n",
        "print(\"Shape:\", token_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdip4G-Zqu16",
        "outputId": "e93a29c0-02cc-488f-c9ae-4439fe3c1b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.1212,  0.3516, -0.0730,  ..., -0.3403,  0.2087,  0.3752],\n",
            "         [ 0.2480,  0.3334, -0.1770,  ..., -0.2022,  0.5678,  0.1120],\n",
            "         [ 0.8236, -0.1229,  1.1042,  ..., -0.1084,  0.4627, -0.2217],\n",
            "         [ 0.2773, -0.1071,  0.9779,  ..., -1.5229,  0.5047,  0.9493],\n",
            "         [ 0.3514,  0.5343, -0.2563,  ..., -1.0669,  0.0827,  0.1577],\n",
            "         [ 0.7256,  0.1635, -0.3260,  ...,  0.0015, -0.5861, -0.4024]]])\n",
            "Shape: torch.Size([1, 6, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBAp74Uour7c",
        "outputId": "200ab160-1f42-4c5f-cdd4-05786309a2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 1045, 2215, 1037, 3899,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBQtdHj4vT5E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}