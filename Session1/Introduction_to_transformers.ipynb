{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7450b57b",
      "metadata": {},
      "source": [
        "# Introduction to Transformers\n",
        "\n",
        "### Objective:\n",
        "Familiarise yourself with the Huggingface transformer components such as tokenizers, models and try out some basic applications with Pipelines.\n",
        "\n",
        "1. [Huggingface Models](https://huggingface.co/models) : Familiarise yourself on how to select models for certain tasks, languages.\n",
        "2. [Huggingface Datasets](https://huggingface.co/datasets) : Explore the different datasets and observe how certain datasets are suitable for certain tasks.\n",
        "3. [Hugginface Documentation](https://huggingface.co/docs) : Familiarise yourself with the documentation of Huggingface. \n",
        "4. [Huggingface LLM Course](https://huggingface.co/learn/llm-course/chapter1/1) **[Recommended Self-Study]**\n",
        "\n",
        "\n",
        "#### Models\n",
        "Models are transformer based and can be encoder, decoder or encoder-decoder categories.\n",
        "\n",
        "#### Tokenizers\n",
        "\n",
        "The tokenizer is responsible for breaking down the input sequence into a set of tokens. They return a list of input_ids, token_type_ids and attention_mask\n",
        "1. **input_ids** are token indices, numerical representations of tokens building the sequences that will be used as input by the model.\n",
        "2. **attention_mask** is a binary tensor which indicates to the model which tokens should be attended to, and which should not (padded values are marked as 0).\n",
        "3. **token_type_ids** are useful for applications where more than one sequences are present such as sequence classification or question answering. These require two different sequences to be joined in a single “input_ids” entry, which usually is performed with the help of special tokens, such as the classifier ([CLS]) and separator ([SEP]) tokens. \n",
        "\n",
        "#### Pipelines\n",
        "Pipelines are an abstraction under which a model is connected inclduing the required preprocessing and postprocessing steps, allowing us to directly input any text and get a suitable answer. More information on the type of pipelines [here.](https://github.com/huggingface/transformers/tree/main/src/transformers/pipelines)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "81f439db",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/storage/homefs/sn23a250/CAS_NLP_M4/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a7d20394",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b6b9d631",
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"I love the CAS in NLP a lot!!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8691ea80",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1045, 2293, 1996, 25222, 1999, 17953, 2361, 1037, 2843, 999, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7701acd0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c6d40b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db120695",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5106b0c2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2519542",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c0ecfd9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db571bc",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22bf3136",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55771237",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python(cas-nlp)",
      "language": "python",
      "name": "cas-nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
