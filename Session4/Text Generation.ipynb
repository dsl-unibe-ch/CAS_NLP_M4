{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9450d1b-18b6-4dc9-9422-3cd434d8195a",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "\n",
    "This notebook helps to understand how text generation models may be further finetuned for certain domains. \n",
    "In the example below, at first we prompt a [GPT2 model](https://huggingface.co/openai-community/gpt2) with some medical condition.\n",
    "Then we use a [medical dataset](https://huggingface.co/datasets/gamino/wiki_medical_terms) to try and improve the generation for this domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a1a2ee4-c0ae-437e-a37c-d0f780db9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0662ef9-3e36-49e2-a20c-dc5241a535fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\", device = \"cuda\", model_kwargs={\"max_length\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7178ec0-beff-470f-85be-7c587678a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I went to the bakery and ate a bagel. Now my stomach hurts. I think I have icky poo and my mouth is burning.\\n\\nI tried to pick up the bagel and was kind of disappointed because it was so close, but that\\'s okay. I got it next to me. I went to the bakery and I saw the bagel.\\n\\nWhen I opened the bagel I was so upset. I have a lot of friends and I\\'m not alone. It\\'s the only bagel in the Whole Foods. It\\'s a bagel. I\\'m kind of scared.\\n\\nI was crying when I saw the bagel.\\n\\nIt was so good. I was so happy.\\n\\nI started to cry. I was so happy.\\n\\nI was so happy.\\n\\nI was so happy.\\n\\nI felt so good.\\n\\nI was so happy.\\n\\nI had so many friends who have been there for me.\\n\\nI had so many friends who\\'ve been there for me. I have so many friends who have been with me. I was so happy.\\n\\nMy friends are like, \"This is my friend.\"\\n\\nMy friends are like, \"This is my friend.\"\\n\\nMy friends are like, \"This is my friend.\"\\n\\nI\\'m so happy.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_generate = \"I went to the bakery and ate a bagel. Now my stomach hurts. I think I have \"\n",
    "pipe(prompt_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "215f3ed8-be3e-4b04-80af-47661b74a777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e68fca923c4a7dae0c9fa1a4686860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2308be28eebf4882b6fcc822db6a04ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1373 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset('gamino/wiki_medical_terms')\n",
    "train_val = dataset[\"train\"].train_test_split(\n",
    "    test_size=0.2, seed=42)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_val[\"train\"],\n",
    "    \"validation\": train_val[\"test\"]\n",
    "})\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('openai-community/gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples['page_text'], truncation=True, padding='max_length', max_length=128)\n",
    "    inputs['labels'] = inputs['input_ids'].copy()\n",
    "    return inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=['page_title', 'page_text', '__index_level_0__'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0be9ef8-5b0e-4ebc-b09a-39ba527393a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['page_title', 'page_text', '__index_level_0__'],\n",
       "        num_rows: 5488\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['page_title', 'page_text', '__index_level_0__'],\n",
       "        num_rows: 1373\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8018ed9c-d269-4b21-8de6-c09e649bcc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5488\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1373\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc51fcf8-ea5a-4c9a-aa79-0071eb7647d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =AutoModelForCausalLM.from_pretrained('openai-community/gpt2').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf1e95d-9e6c-477d-9482-5adaceecafd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2744' max='2744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2744/2744 01:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.898000</td>\n",
       "      <td>2.694345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.593700</td>\n",
       "      <td>2.653255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2744, training_loss=2.771134757439527, metrics={'train_runtime': 107.3711, 'train_samples_per_second': 102.225, 'train_steps_per_second': 25.556, 'total_flos': 716985335808000.0, 'train_loss': 2.771134757439527, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='models/results',\n",
    "    eval_strategy='epoch',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='models/logs'\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbacc376-1246-4ec0-b5fd-ea63c0b20199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/gpt2/tokenizer_config.json',\n",
       " 'models/gpt2/special_tokens_map.json',\n",
       " 'models/gpt2/vocab.json',\n",
       " 'models/gpt2/merges.txt',\n",
       " 'models/gpt2/added_tokens.json',\n",
       " 'models/gpt2/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# save the model and tokenizer explicitly\n",
    "model_output_dir = 'models/gpt2/'\n",
    "\n",
    "model.save_pretrained(model_output_dir)\n",
    "tokenizer.save_pretrained(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b49d8951-1ff8-47b1-82b6-1c370366a4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pipe_causal_lm_finetuned = pipeline(\"text-generation\", model=\"models/gpt2\", device = \"cuda\", model_kwargs={\"max_length\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b00a89a3-a185-47ea-9c33-f2130da7c87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I went to the bakery and ate a bagel. Now my stomach hurts. I think I have ileotosis. I\\'m in pain. I think I have diarrhea. I have vomiting. I am so tired I am vomiting. And I think I have a migraine.\"\\n\\n\"You can\\'t just say that. There are so many people who are in pain. There are people who have had surgery, cancer, and they\\'re so tired. But they have no way to stop pain. There is no way to stop them from doing what they\\'re doing. I think my stomach\\'s going to be very unbalanced. I think it\\'s going to be a very difficult day.\"\\n\\n\"I feel so sick. I\\'m going to come out of this with all my bones. I\\'m going to fall ill. I\\'m going to lose a lot of muscle. I\\'m going to have a bad headache. I\\'m going to have a bad break in my heart. I\\'m going to have a bad, broken heart.\"\\n\\n\"I just don\\'t think I\\'m going to be able to do something that will save me. I can\\'t do it. I don\\'t know what I am going to do. I can\\'t do anything. I can\\'t do anything. I can\\'t do anything. I need to find a way.\"\\n\\n\"I'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(prompt_generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c65479e-8efa-4a7b-adde-dd43a4d5d8fd",
   "metadata": {},
   "source": [
    "# To Do\n",
    "1. Discuss if there is any improvement in the text generation as a result of the prompting.\n",
    "2. What happens if you swap the model with a different Decoder only model such as (gpt2-xl, google/gemma-2b, mistralai/Mistral-7B-v0.1)?\n",
    "3. What happens if you finetune in a different domain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da397551-029e-4ba5-95d1-16483beccab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_kernel",
   "language": "python",
   "name": "conda_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
