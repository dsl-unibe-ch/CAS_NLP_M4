{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9450d1b-18b6-4dc9-9422-3cd434d8195a",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "\n",
    "This notebook helps to understand how text generation models may be further finetuned for certain domains. \n",
    "In the example below, at first we prompt a [GPT2 model](https://huggingface.co/openai-community/gpt2) with some medical condition.\n",
    "Then we use a [medical dataset](https://huggingface.co/datasets/gamino/wiki_medical_terms) to try and improve the generation for this domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a1a2ee4-c0ae-437e-a37c-d0f780db9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0662ef9-3e36-49e2-a20c-dc5241a535fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\", device = \"cuda\", model_kwargs={\"max_length\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7178ec0-beff-470f-85be-7c587678a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I went to the bakery and ate a bagel. Now my stomach hurts. I think I have ileostomy. I need to eat more food. I don\\'t want to go to the doctor, I just want to go to the doctor and get better.\"\\n\\nHe then gave his family a short video description of the procedure, which was posted on his Facebook page.\\n\\n\"I\\'m sorry, but I am a full-fledged cancer survivor, so I can\\'t speak for the entire community.\"\\n\\nHe was also seen on Twitter, writing: \"Please help me get better. I am so sick. I am trying to be good to everyone. I can\\'t even go to the doctor. Please find me a doctor.\"\\n\\nHe later posted a video on Instagram of himself walking down the street, standing at a gas station and talking to customers.\\n\\n\"I want to thank all of the people I met and all the people who came to visit me. I\\'m so grateful. Thank you so much.\"\\n\\nThe mother of a friend, who also called for help after the incident, said she had seen her son on Twitter and that she was very upset.\\n\\n\"I\\'m so sick. I am trying to be good to everybody. I can\\'t even go to the doctor. Please help me get better.\"\\n\\nA'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_generate = \"I went to the bakery and ate a bagel. Now my stomach hurts. I think I have \"\n",
    "pipe(prompt_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215f3ed8-be3e-4b04-80af-47661b74a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset('gamino/wiki_medical_terms')\n",
    "train_val = dataset[\"train\"].train_test_split(\n",
    "    test_size=0.2, seed=42)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_val[\"train\"],\n",
    "    \"validation\": train_val[\"test\"]\n",
    "})\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('openai-community/gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples['page_text'], truncation=True, padding='max_length', max_length=128)\n",
    "    inputs['labels'] = inputs['input_ids'].copy()\n",
    "    return inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=['page_title', 'page_text', '__index_level_0__'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0be9ef8-5b0e-4ebc-b09a-39ba527393a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_title': 'Amédée Galzin',\n",
       " 'page_text': 'Amédée Galzin (1 May 1853, Parrinet, Aveyron – 14 February 1925, Parrinet) was a French veterinarian and mycologist.\\nIn 1878 he obtained his degree from the veterinary college in Toulouse. From 1879 to 1905, he served as a military veterinarian, becoming a knight of the Legion of Honour in 1899.With Abbé Hubert Bourdot, he was co-author of a series of publications (11 parts, 1909 to 1925) involving Hymenomycetes native to France; all parts being published in the Bulletin de la Société Mycologique de France. With Bourdot, he also wrote Heterobasidiae nondum descriptae (Descriptions of a few jelly fungi).With Bourdot, he was the taxonomic authority of the fungi genus Oxyporus, as well as of numerous mycological species.\\n\\n\\n== References ==',\n",
       " '__index_level_0__': 3481}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8018ed9c-d269-4b21-8de6-c09e649bcc96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5488\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1373\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc51fcf8-ea5a-4c9a-aa79-0071eb7647d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =AutoModelForCausalLM.from_pretrained('openai-community/gpt2').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecf1e95d-9e6c-477d-9482-5adaceecafd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2744' max='2744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2744/2744 01:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.898000</td>\n",
       "      <td>2.694345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.593700</td>\n",
       "      <td>2.653255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2744, training_loss=2.771134757439527, metrics={'train_runtime': 108.9743, 'train_samples_per_second': 100.721, 'train_steps_per_second': 25.18, 'total_flos': 716985335808000.0, 'train_loss': 2.771134757439527, 'epoch': 2.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='models/results',\n",
    "    eval_strategy='epoch',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='models/logs'\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbacc376-1246-4ec0-b5fd-ea63c0b20199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/gpt2/tokenizer_config.json',\n",
       " 'models/gpt2/special_tokens_map.json',\n",
       " 'models/gpt2/vocab.json',\n",
       " 'models/gpt2/merges.txt',\n",
       " 'models/gpt2/added_tokens.json',\n",
       " 'models/gpt2/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# save the model and tokenizer explicitly\n",
    "model_output_dir = 'models/gpt2/'\n",
    "\n",
    "model.save_pretrained(model_output_dir)\n",
    "tokenizer.save_pretrained(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b49d8951-1ff8-47b1-82b6-1c370366a4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pipe_causal_lm_finetuned = pipeline(\"text-generation\", model=\"models/gpt2\", device = \"cuda\", model_kwargs={\"max_length\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b00a89a3-a185-47ea-9c33-f2130da7c87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I went to the bakery and ate a bagel. Now my stomach hurts. I think I have  stomachache. I eat a lot of bread and some raw meat. I have a small appetite. I feel tired. The next day, I feel like I am in a coma. I feel sick, but I am not in a coma either. I am in my mid-30s now. I am in a state of shock, but I am still recovering from my stomachache.My stomachache is caused by the presence of a gastric acid, usually at the site of the stomach attack. This can be caused by the presence of a gastric acid, in the lower intestine, or the presence of a large acid in the stomach. It is most often caused by the presence of a large androgen receptor-positive gastric acid (GARPA).\\nI am not a risk factor for gastric acidosis. However, in my experience, GARPA is one of the most common risk factors, and is extremely rare.\\n\\nCauses\\nThe most common cause of gastric acidosis is a drug-induced gastric acidosis.  It is triggered by drugs interfering with the enzyme GABAA.  This leads to high levels of gastric acid in the bloodstream.  GABAA is the enzyme that converts blood sugars into ketones'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_causal_lm_finetuned(prompt_generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c65479e-8efa-4a7b-adde-dd43a4d5d8fd",
   "metadata": {},
   "source": [
    "# To Do\n",
    "1. Discuss if there is any improvement in the text generation as a result of the finetuning.\n",
    "2. What happens if you swap the model with a different Decoder only model such as (gpt2-xl, google/gemma-2b, mistralai/Mistral-7B-v0.1)?\n",
    "3. What happens if you finetune in a different domain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da397551-029e-4ba5-95d1-16483beccab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_kernel",
   "language": "python",
   "name": "conda_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
