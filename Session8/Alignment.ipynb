{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a96f6e0-1e88-4d45-b35b-7778c45d07da",
   "metadata": {},
   "source": [
    "# LoRA and Alignment\n",
    "The goal of this notebook is to finetune a given model for Instruction Finetuning using Lora and Alignment over the dataset [ultrafeedback_binarized](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized).\n",
    "\n",
    "### Reading and Links\n",
    "1. https://huggingface.co/docs/trl/main/en/index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74384cc5-cef1-403a-a9fd-2c2b1c27557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig, DPOTrainer, DPOConfig\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa3c76d-f1a6-486a-bd2d-ce39dd246f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f7cfa9a-47fa-4aab-bdaa-707c6612ee68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabf03a7ffea41d7bb94f52a4d4b9b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"   # swap to a 7B instruct model if you prefer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf656fb5-b112-4037-909c-bcd1b51f0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\", split=\"train_sft\").select(range(1000)) # prompt/chosen/rejected\n",
    "def tok_len(s): \n",
    "    return len(tokenizer(s, add_special_tokens=False)[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "294f0713-fbb7-4399-8a09-290d03b79ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_assistant_content(msgs):\n",
    "    # msgs: list of {\"role\": \"...\", \"content\": \"...\"}\n",
    "    for m in reversed(msgs):\n",
    "        if isinstance(m, dict) and m.get(\"role\") == \"assistant\":\n",
    "            return m.get(\"content\", \"\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ccaa2f2-efe8-4fb9-9073-39d716b285cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'how can i develop a habit of drawing daily',\n",
       " 'prompt_id': '086b3e24f29b8956a01059f79c56db35d118a06fb6b844b095737d042795cd43',\n",
       " 'chosen': [{'content': 'how can i develop a habit of drawing daily',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
       "   'role': 'assistant'}],\n",
       " 'rejected': [{'content': 'how can i develop a habit of drawing daily',\n",
       "   'role': 'user'},\n",
       "  {'content': \"As an AI language model, I cannot personally develop habits for you. But, here are some tips for developing a habit of drawing daily:\\n\\n1. Start small: Start with simple drawings or doodles and gradually increase the complexity of your drawings.\\n\\n2. Set a schedule: Set a specific time every day to draw, and try to stick to it as much as possible.\\n\\n3. Make it fun: Don't pressure yourself to create masterpieces every time you draw. Make it a relaxing and enjoyable experience.\\n\\n4. Use resources: There are many drawing tutorials available online. Use resources like YouTube or online drawing courses to help you improve your skills.\\n\\n5. Surround yourself with inspiration: Expose yourself to a variety of art forms, such as paintings, illustrations, and photographs, to inspire and motivate you.\\n\\nRemember, everyone has their own creative style and pace. Just keep practicing and enjoying the process of drawing.\",\n",
       "   'role': 'assistant'}],\n",
       " 'messages': [{'content': 'how can i develop a habit of drawing daily',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
       "   'role': 'assistant'}],\n",
       " 'score_chosen': 8.5,\n",
       " 'score_rejected': 8.5}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0048f11-9df6-400e-9b30-cb899b21a3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb81ccd771f4016b6c26e3ba11d2f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_f = ds.filter(\n",
    "    lambda x: tok_len(x[\"prompt\"]) <= 256\n",
    "    and tok_len(get_last_assistant_content(x[\"chosen\"])) <= 256\n",
    "    and tok_len(get_last_assistant_content(x[\"rejected\"])) <= 256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f3f88df-6e26-48fc-b8f3-aa8fec51c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = ds_f.train_test_split(test_size=100, seed=42)\n",
    "train_raw, eval_raw = split[\"train\"], split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52e8b984-3ce4-4f44-9f70-909d0d382df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
       "    num_rows: 254\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "faf9bf04-4650-48eb-9795-63b82eaa511d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637239b6ab6d40d0937b2254662adedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec036b9abe040da9ceff288d70158b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c18835b0f548ef9daa83bd827e8f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c602001da8024a8a8b76c0448accff9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SYSTEM = \"You are a helpful university helpdesk assistant. Be concise and ask clarifying questions when needed.\"\n",
    "\n",
    "def build_chat_prompt(user: str) -> str:\n",
    "    msgs = [{\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": user}]\n",
    "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "        return tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "    return f\"System: {SYSTEM}\\nUser: {user}\\nAssistant:\"\n",
    "\n",
    "def to_dpo_row(ex):\n",
    "    return {\n",
    "        \"prompt\": build_chat_prompt(ex[\"prompt\"]),                # string\n",
    "        \"chosen\": get_last_assistant_content(ex[\"chosen\"]),       # string\n",
    "        \"rejected\": get_last_assistant_content(ex[\"rejected\"]),   # string\n",
    "    }\n",
    "\n",
    "train_dpo = train_raw.map(to_dpo_row, remove_columns=train_raw.column_names)\n",
    "eval_dpo  = eval_raw.map(to_dpo_row,  remove_columns=eval_raw.column_names)\n",
    "\n",
    "train_sft = train_dpo.map(lambda x: {\"prompt\": x[\"prompt\"], \"completion\": x[\"chosen\"]},\n",
    "                          remove_columns=[\"chosen\",\"rejected\"])\n",
    "eval_sft  = eval_dpo.map(lambda x: {\"prompt\": x[\"prompt\"], \"completion\": x[\"chosen\"]},\n",
    "                         remove_columns=[\"chosen\",\"rejected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "226d0d17-add0-4786-afa7-681f0e0c801b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '<|im_start|>system\\nYou are a helpful university helpdesk assistant. Be concise and ask clarifying questions when needed.<|im_end|>\\n<|im_start|>user\\nWrite a 10-line free verse poem about the contagious joys of laughter with a focus on the physical and emotional benefits it provides. Use descriptive language to evoke a vivid image of a joyful moment shared among friends, and include at least one metaphor or simile to express the power of laughter to uplift spirits and connect people.<|im_end|>\\n<|im_start|>assistant\\n',\n",
       " 'chosen': \"Laughter, a medicine for the soul,\\nSpreading joy, like a wildfire's embrace,\\nContagious and pure, it warms the heart,\\nBringing people together, like a work of art.\\n\\nA shared laugh, a bonding moment,\\nCreates a connection, like a river's flow,\\nThrough the laughter, our spirits are lifted,\\nLike a bird taking flight, our hearts are alifted.\\n\\nThe power of laughter, it heals and mends,\\nLike a gentle breeze, it soothes and sends,\\nA message of love, a beam of light,\\nBringing us closer, like rays of sunlight.\\n\\nIt's a universal language, a sign,\\nThat we're all in this together, all divine,\\nA smile, a chuckle, a roar,\\nLaughter unites us, forevermore.\\n\\nSo let's embrace it, let's laugh out loud,\\nLike a rainbow, after a stormy cloud,\\nFor in this joy, we find our strength,\\nA bond that's built to last, a true length.\",\n",
       " 'rejected': 'Laughter, a contagious virus\\nSpreads joy and warmth among all users\\nEvoking feelings of happiness and bliss\\nRelieves stress from the trials and tribulations\\nScratches the itch of an ornery mood\\nAs ticklish violations of time and space.\\nCrucial to the maintenance of emotional balance\\nChuckles ultimately turn into deep belly laughs\\nAs exclamations of joy emerge from within.\\nLaughter creates an atmosphere of positive energy\\nGently coaxing out the inner free spirit of you and me.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dpo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "002f9cc9-6b12-4af0-9ba1-e660018b9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "422012e5-da7f-4d49-b3c1-75f82982852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/sn23a250/.local/lib/python3.11/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/storage/homefs/sn23a250/.local/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea41b7658e3f40e0a800969bfd39b222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3a1756a28648a4bbdd51017a654355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b02602b9bd4c2cb325c51fe577680e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a7c4ec2fee44cc9388330e91341e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73cbf01ffa340fea4cae922b8897241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87367c72919f4934b80bd69d71d32c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390df40b4fff4f0db6f78cf7a241b3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5dbc28649942848ad6d5e005f382e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c3930ade684cbbadbc15885395246e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f474ec15af45288a595214de39228a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sft_out = \"sft_lora\"\n",
    "\n",
    "sft_cfg = SFTConfig(\n",
    "    output_dir=sft_out,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    logging_steps=10,\n",
    "    save_steps=200,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_total_limit=2,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=None,\n",
    ")\n",
    "\n",
    "sft_trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_cfg,\n",
    "    train_dataset=train_sft,\n",
    "    eval_dataset=eval_sft,\n",
    "    processing_class=tokenizer,\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e34ceac2-8a76-4ae7-8a15-0e4f506e94e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sft_trainer.train()\n",
    "sft_trainer.save_model(sft_out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0426b7c0-3dc6-48b7-881b-2317e4851e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_inference(m):\n",
    "    m.eval()\n",
    "    # Disable gradient checkpointing for generation\n",
    "    if hasattr(m, \"gradient_checkpointing_disable\"):\n",
    "        m.gradient_checkpointing_disable()\n",
    "    # Re-enable cache for faster generation\n",
    "    if hasattr(m, \"config\"):\n",
    "        m.config.use_cache = True\n",
    "    return m\n",
    "\n",
    "def generate(m, user_text, max_new_tokens=160, temperature=0.7, BF16=torch.float16):\n",
    "    m = prepare_for_inference(m)\n",
    "\n",
    "    prompt = build_chat_prompt(user_text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(m.device)\n",
    "\n",
    "    # Choose autocast dtype\n",
    "    amp_dtype = torch.bfloat16 if (m.device.type == \"cuda\" and BF16) else torch.float16\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if m.device.type == \"cuda\":\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=amp_dtype):\n",
    "                out = m.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    do_sample=True,\n",
    "                    temperature=temperature,\n",
    "                )\n",
    "        else:\n",
    "            out = m.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "908fe06f-aeaa-40c7-bb46-3e4cf5a27bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASE ===\n",
      "system\n",
      "You are a helpful university helpdesk assistant. Be concise and ask clarifying questions when needed.\n",
      "user\n",
      "I forgot my Uni email password. What should I do?\n",
      "assistant\n",
      "If you have forgotten your Uni email password, there are a few steps you can take to reset it:\n",
      "\n",
      "1. Go to the University's online helpdesk or support page.\n",
      "2. Look for a \"Forgot Password\" or \"Reset Password\" option on the login page or in the account settings section.\n",
      "3. Follow the instructions provided by the website to reset your password. This may involve answering security questions, receiving a link via email, or using a mobile app.\n",
      "\n",
      "If these options are not available, you can also contact the IT Helpdesk directly for assistance.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== BASE ===\")\n",
    "print(generate(model, \"I forgot my Uni email password. What should I do?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "308ffa4c-b1b4-4150-817c-33f7a5e4da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/sn23a250/.local/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AFTER SFT ===\n",
      "system\n",
      "You are a helpful university helpdesk assistant. Be concise and ask clarifying questions when needed.\n",
      "user\n",
      "I forgot my Uni email password. What should I do?\n",
      "assistant\n",
      "You can reset your Uni email password by following these steps:\n",
      "\n",
      "1. Go to the uni's website and click on \"Forgot Password?\" or \"Reset Password?\"\n",
      "2. Enter your University email address.\n",
      "3. Follow the instructions to reset your password.\n",
      "\n",
      "If you don't know your email address, contact the Student Services office for assistance.\n"
     ]
    }
   ],
   "source": [
    "# After SFT\n",
    "sft_eval = PeftModel.from_pretrained(model, sft_out)\n",
    "sft_eval.eval()\n",
    "print(\"\\n=== AFTER SFT ===\")\n",
    "print(generate(sft_eval, \"I forgot my Uni email password. What should I do?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca160f-5c4e-44d7-8e80-510d795dd614",
   "metadata": {},
   "source": [
    "# Reload the base model freshly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c314f-ad3a-475b-8067-eeded90e7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model2 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f647d827-3923-4acf-8a35-0ef42d4b10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbb560d705a4f40945344ed5d40ac65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train dataset reference log probs:   0%|          | 0/254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 01:32, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dpo_out = \"dpo_lora\"\n",
    "policy_model = PeftModel.from_pretrained(model2, sft_out, is_trainable=True)\n",
    "\n",
    "dpo_cfg = DPOConfig(\n",
    "    output_dir=dpo_out,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    logging_steps=10,\n",
    "    save_steps=200,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_total_limit=2,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=None,\n",
    "    beta=0.1,\n",
    "    max_prompt_length=256,\n",
    "    max_completion_length=256,# Helps single-GPU memory: precompute ref logprobs so ref model needn't stay resident :contentReference[oaicite:9]{index=9}\n",
    "    precompute_ref_log_probs=True,\n",
    "    precompute_ref_batch_size=1,\n",
    ")\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=policy_model,\n",
    "    args=dpo_cfg,\n",
    "    train_dataset=train_dpo,\n",
    "    eval_dataset=eval_dpo,\n",
    "    processing_class=tokenizer,\n",
    "    # (prompt, chosen, rejected) format; explicit prompts recommended :contentReference[oaicite:10]{index=10}\n",
    ")\n",
    "dpo_trainer.train()\n",
    "dpo_trainer.save_model(dpo_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04ae529b-dd80-44f1-9bec-017dcef2d478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/sn23a250/.local/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AFTER DPO ===\n",
      "system\n",
      "You are a helpful university helpdesk assistant. Be concise and ask clarifying questions when needed.\n",
      "user\n",
      "I forgot my Uni email password. What should I do?\n",
      "assistant\n",
      "If you've forgotten your University of X email password, you can reset it by following these steps:\n",
      "\n",
      "1. Go to the [University's Password Reset Page](https://www.universityofx.com/password-reset)\n",
      "2. Enter your University of X email address in the provided field.\n",
      "3. Click on \"Reset Password\".\n",
      "4. A new password will be sent to the email address associated with your account.\n",
      "\n",
      "If you don't have access to your email or you're not able to reset your password, you may need to contact the IT Helpdesk for assistance.\n"
     ]
    }
   ],
   "source": [
    "# After DPO\n",
    "dpo_eval = PeftModel.from_pretrained(model, sft_out)\n",
    "dpo_eval.eval()\n",
    "print(\"\\n=== AFTER DPO ===\")\n",
    "print(generate(dpo_eval, \"I forgot my Uni email password. What should I do?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6edd7-cb81-454b-90ee-c1fdded3b3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-cu128)\n",
   "language": "python",
   "name": "llm-cu128"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
